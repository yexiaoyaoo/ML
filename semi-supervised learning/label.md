å¥½çš„ï¼Œæˆ‘å¯ä»¥å°è¯•å°†ä¹‹å‰çš„åŠç›‘ç£å­¦ä¹ æ–¹æ³•å’Œç°åœ¨çš„å¾ªç¯æŒ–æ˜æ–¹æ³•æ•´åˆåˆ°ä¸€èµ·ï¼Œä½ å¯ä»¥æ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚å’Œæ•°æ®è¿›è¡Œä¿®æ”¹å’Œä¼˜åŒ–ã€‚

é¦–å…ˆï¼Œä½ éœ€è¦å¯¼å…¥ä¸€äº›å¿…è¦çš„åº“ï¼Œä¾‹å¦‚jieba, re, pandas, sklearnç­‰ï¼š

```python
import jieba
import jieba.posseg as pseg
import re
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.semi_supervised import SelfTrainingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
```

ç„¶åï¼Œä½ éœ€è¦è¯»å–æ•°æ®ï¼Œå¹¶å°†æœ‰æ ‡ç­¾æ•°æ®å’Œæ— æ ‡ç­¾æ•°æ®åˆå¹¶ä¸ºä¸€ä¸ªæ•°æ®æ¡†ï¼Œå¹¶ç”¨-1è¡¨ç¤ºæ— æ ‡ç­¾æ•°æ®çš„æ ‡ç­¾ï¼š

```python
# Read labeled data
labeled_df = pd.read_csv("labeled_data.csv")
# Read unlabeled data
unlabeled_df = pd.read_csv("unlabeled_data.csv")
# Assign -1 to unlabeled data labels
unlabeled_df["label"] = -1
# Concatenate labeled and unlabeled data
data_df = pd.concat([labeled_df, unlabeled_df], ignore_index=True)
```

æ¥ä¸‹æ¥ï¼Œä½ éœ€è¦å®šä¹‰ä¸€äº›è¯„ä»·å¯¹è±¡å’Œè¯„ä»·è§‚ç‚¹çš„æŠ½å–è§„åˆ™ï¼Œè¿™é‡Œæˆ‘ä»¬å‚è€ƒè®ºæ–‡ä¸­ç»™å‡ºçš„è§„åˆ™ï¼Œä¾‹å¦‚ï¼š

- è¯„ä»·å¯¹è±¡ï¼šåè¯æˆ–åè¯çŸ­è¯­
- è¯„ä»·è§‚ç‚¹ï¼šå½¢å®¹è¯æˆ–åŠ¨è¯çŸ­è¯­
- è¯„ä»·å¯¹è±¡å’Œè¯„ä»·è§‚ç‚¹ä¹‹é—´çš„ä¾å­˜å…³ç³»ï¼šä¸»è°“å…³ç³»ã€å®šä¸­å…³ç³»ã€åŠ¨å®¾å…³ç³»ã€ä»‹å®¾å…³ç³»ç­‰

ç„¶åï¼Œä½ éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æ ¹æ®è§„åˆ™ä»è¯„è®ºæ–‡æœ¬ä¸­æŠ½å–è¯„ä»·å¯¹è±¡å’Œè¯„ä»·è§‚ç‚¹ï¼Œå¹¶è¿”å›ä¸€ä¸ªå…ƒç»„åˆ—è¡¨ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨jiebaè¿›è¡Œåˆ†è¯å’Œè¯æ€§æ ‡æ³¨ï¼Œå¹¶ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä¾å­˜å…³ç³»ï¼Œä¾‹å¦‚ï¼š

```python
def extract_object_and_opinion(text):
  # Initialize an empty list to store the results
  results = []
  # Segment the text with jieba and get the words and tags
  words, tags = zip(*pseg.cut(text))
  # Join the words and tags with "/" as delimiter
  text_with_tags = "/".join([word + "/" + tag for word, tag in zip(words, tags)])
  # Define a regular expression pattern to match the object and opinion pairs
  pattern = r"((?:[^\s/]+/n(?:s|z|t|f|g|r|x)?)+)([^\s/]+/v(?:n|d|i|g|p)?)([^\s/]+/a(?:n|d|g)?)(?![^\s/]+/u)"
  # Find all the matches in the text with tags
  matches = re.findall(pattern, text_with_tags)
  # Loop through each match
  for match in matches:
    # Get the object, verb and adjective from the match
    object, verb, adjective = match
    # Remove the tags from the object, verb and adjective
    object = re.sub(r"/\w+", "", object)
    verb = re.sub(r"/\w+", "", verb)
    adjective = re.sub(r"/\w+", "", adjective)
    # Append the object and opinion tuple to the results list
    results.append((object, verb + adjective))
  # Return the results list
  return results
```

æ¥ä¸‹æ¥ï¼Œä½ éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æ ¹æ®è¯„è®ºæ¨¡å¼å’Œè¯„è®ºç§å­è¿›è¡ŒåŒ¹é…ï¼Œå¹¶è¿”å›ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦åŒ¹é…æˆåŠŸï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨jiebaè¿›è¡Œåˆ†è¯ï¼Œå¹¶ä½¿ç”¨å­—ç¬¦ä¸²åŒ¹é…ï¼Œä¾‹å¦‚ï¼š

```python
def match_pattern_and_seed(text, pattern, seed):
  # Segment the text with jieba and get the word list
  text_words = list(jieba.cut(text))
  # Segment the pattern with jieba and get the word list
  pattern_words = list(jieba.cut(pattern))
  # Segment the seed with jieba and get the word list
  seed_words = list(jieba.cut(seed))
  # Initialize a boolean variable to store the match result
  match = True
  # Loop through each word in the pattern word list
  for i, pattern_word in enumerate(pattern_words):
    # Check if the pattern word is a wildcard symbol "*"
    if pattern_word == "*":
      # Skip this word and continue to the next one
      continue
    # Check if the pattern word is out of range of the text word list or seed word list
    elif i >= len(text_words) or i >= len(seed_words):
      # Set match to False and break the loop
      match = False
      break
    # Check if the pattern word matches the text word and seed word 
    elif pattern_word == text_words[i] and pattern_word == seed_words[i]:
      # Continue to the next word
      continue
    # Otherwise, set match to False and break the loop
    else:
      match = False
      break
  # Return the match result
  return match
```

æ¥ä¸‹æ¥ï¼Œä½ éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥ä»å€™é€‰è¯„è®ºæ¨¡å¼åº“ä¸­æŠ½å–æ–°çš„è¯„è®ºç§å­ï¼Œå¹¶è¿”å›ä¸€ä¸ªè¯„è®ºç§å­åˆ—è¡¨ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨éšæœºæŠ½æ ·çš„æ–¹æ³•ï¼Œä¾‹å¦‚ï¼š

```python
def extract_new_seeds(candidates, k):
  # Initialize an empty list to store the new seeds
  new_seeds = []
  # Shuffle the candidates list randomly
  np.random.shuffle(candidates)
  # Loop through the first k candidates
  for candidate in candidates[:k]:
    # Get the comment text from the candidate tuple
    comment = candidate[0]
    # Append the comment text to the new seeds list
    new_seeds.append(comment)
  # Return the new seeds list
  return new_seeds
```

æ¥ä¸‹æ¥ï¼Œä½ éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æ„å»ºå€™é€‰è¯„è®ºæ¨¡å¼åº“ï¼Œå¹¶è¿”å›ä¸€ä¸ªå€™é€‰è¯„è®ºæ¨¡å¼åˆ—è¡¨ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨è¯„ä»·å¯¹è±¡å’Œè¯„ä»·è§‚ç‚¹çš„æŠ½å–ç»“æœå’Œè¯„è®ºç§å­è¿›è¡ŒåŒ¹é…ï¼Œä¾‹å¦‚ï¼š

```python
def build_candidate_patterns(comments, seeds):
  # Initialize an empty list to store the candidate patterns
  candidates = []
  # Loop through each comment and label pair in the comments list
  for comment, label in comments:
    # Extract the object and opinion from the comment
    object_and_opinion = extract_object_and_opinion(comment)
    # Loop through each object and opinion pair in the object and opinion list
    for object, opinion in object_and_opinion:
      # Loop through each seed in the seeds list
      for seed in seeds:
        # Check if the object and opinion pair matches the seed
        if match_pattern_and_seed(object + opinion, "*å¥½ç”¨", seed):
          # Construct a candidate pattern with a wildcard symbol "*"
          candidate_pattern = "*å¥½ç”¨"
          # Append the candidate pattern, comment and label tuple to the candidates list
          candidates.append((candidate_pattern, comment, label))
        elif match_pattern_and_seed(object + opinion, "*å¡", seed):
          # Construct a candidate pattern with a wildcard symbol "*"
          candidate_pattern = "*å¡"
          # Append the candidate pattern, comment and label tuple to the candidates list
          candidates.append((candidate_pattern, comment, label))
        elif match_pattern_and_seed(object + opinion, "*å¢åŠ *", seed):
          # Construct a candidate pattern with two wildcard symbols "*"
          candidate_pattern = "*å¢åŠ *"
          # Append the candidate pattern, comment and label tuple to the candidates list
          candidates.append((candidate_pattern, comment, label))
  # Return the candidates list
  return candidates
```

æ¥ä¸‹æ¥ï¼Œä½ éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥å¯¹è¯„è®ºæ–‡æœ¬è¿›è¡Œç‰¹å¾æå–ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨TF-IDFå‘é‡ä½œä¸ºç‰¹å¾è¡¨ç¤ºï¼š

```python
def extract_features(texts):
  # Initialize a TF-IDF vectorizer
  vectorizer = TfidfVectorizer()
  # Fit and transform the texts to get feature matrix
  X = vectorizer.fit_transform(texts)
  # Return the feature matrix and vectorizer object 
  return X, vectorizer 
```



æ¥ä¸‹æ¥ï¼Œä½ éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥ç”¨åŠç›‘ç£è‡ªå­¦ä¹ åˆ†ç±»å™¨æ‹Ÿåˆç‰¹å¾çŸ©é˜µå’Œç›®æ ‡æ•°ç»„ï¼Œå¹¶è¿”å›åˆ†ç±»å™¨å¯¹è±¡ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨é€»è¾‘å›å½’ä½œä¸ºåŸºåˆ†ç±»å™¨ï¼Œå¹¶è®¾ç½®ä¸€äº›å‚æ•°ï¼Œä¾‹å¦‚æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç½®ä¿¡åº¦é˜ˆå€¼ç­‰ï¼š

```python
def fit_self_training_classifier(X, y):
  # Initialize a logistic regression classifier as base estimator
  base_estimator = LogisticRegression()
  # Initialize a self-training classifier with the base estimator and some parameters
  stc = SelfTrainingClassifier(base_estimator, max_iter=10, criterion="k_best", k_best=50, verbose=True)
  # Fit the self-training classifier with feature matrix and target array
  stc.fit(X, y)
  # Return the self-training classifier object
  return stc
```

æ¥ä¸‹æ¥ï¼Œä½ éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥ç”¨åŠç›‘ç£è‡ªå­¦ä¹ åˆ†ç±»å™¨å¯¹æ–°çš„è¯„è®ºè¿›è¡Œé¢„æµ‹ï¼Œå¹¶è¿”å›é¢„æµ‹ç»“æœï¼Œä¾‹å¦‚ï¼š

```python
def predict_self_training_classifier(stc, vectorizer, texts):
  # Transform the texts to feature matrix using the vectorizer object
  X = vectorizer.transform(texts)
  # Predict the labels of the texts using the self-training classifier object
  y_pred = stc.predict(X)
  # Return the predicted labels
  return y_pred
```

æœ€åï¼Œä½ å¯ä»¥ç”¨è¿™äº›å‡½æ•°æ¥å®ç°å¾ªç¯æŒ–æ˜çš„è¿‡ç¨‹ï¼Œä¾‹å¦‚ï¼š

```python
# Prepare some initial seeds with labels manually
initial_seeds = [("è½¯ä»¶å¥½ç”¨", "positive"), ("æ¸¸æˆå¡", "negative"), ("åŠŸèƒ½å¢åŠ å¤š", "suggestion")]
# Get only the seed texts from the initial seeds list
seed_texts = [seed[0] for seed in initial_seeds]
# Set a maximum iteration number
max_iter = 10
# Set a number of new seeds to extract each iteration
k = 50

# Loop through each iteration number from 1 to max_iter
for i in range(1, max_iter + 1):
  # Print the iteration number
  print("Iteration:", i)
  # Build a candidate pattern list with comments and labels using current seeds 
  candidates = build_candidate_patterns(data_df[["text", "label"]].values.tolist(), seed_texts)
  # Print the number of candidates found 
  print("Number of candidates:", len(candidates))
  # Extract k new seeds from the candidates list randomly 
  new_seeds = extract_new_seeds(candidates, k)
  # Print the new seeds 
  print("New seeds:", new_seeds)
  # Append the new seeds to the seed texts list 
  seed_texts.extend(new_seeds)
  
  # Extract features from the comment texts in the data frame 
  X, vectorizer = extract_features(data_df["text"])
  # Get the label column as target array
  y = data_df["label"].values
  # Fit a self-training classifier with feature matrix and target array 
  stc = fit_self_training_classifier(X, y)
  
  # Prepare some new comments for testing
  test_comments = ["è¿™ä¸ªAPPçœŸæ˜¯å¤ªæ£’äº†ï¼Œæˆ‘æ¯å¤©éƒ½åœ¨ç”¨", "è¿™ä¸ªAPPæœ‰ç‚¹å¡é¡¿ï¼Œå¸Œæœ›èƒ½ä¼˜åŒ–ä¸€ä¸‹", "è¿™ä¸ªAPPæ²¡æœ‰ä¸­æ–‡ç‰ˆå—ï¼Ÿ"]
  # Predict the labels of the test comments using the self-training classifier and vectorizer 
  test_y_pred = predict_self_training_classifier(stc, vectorizer, test_comments)
  # Print the predicted labels
  print("Predicted labels:", test_y_pred)

å¦‚æœä½ æƒ³å°†è¿™ä¸ªä»£ç æ•´åˆè¿›ä¹‹å‰çš„å¤§é¡¹ç›®é‡Œï¼Œä½ å¯ä»¥ä½¿ç”¨é¢å‘å¯¹è±¡çš„æ€æƒ³ï¼Œå®šä¹‰ä¸€ä¸ªå¾ªç¯æŒ–æ˜çš„ç±»ï¼Œå°†æ‰€æœ‰çš„å‡½æ•°å°è£…æˆç±»çš„æ–¹æ³•ï¼Œç„¶ååœ¨ç±»çš„åˆå§‹åŒ–æ–¹æ³•ä¸­ä¼ å…¥æ•°æ®é›†å’Œä¸€äº›å‚æ•°ï¼Œä¾‹å¦‚ï¼š

```python
class LoopMining:
  # Define the initialization method
  def __init__(self, data_df, initial_seeds, max_iter, k):
    # Assign the data frame to a class attribute
    self.data_df = data_df
    # Assign the initial seeds to a class attribute
    self.initial_seeds = initial_seeds
    # Assign the maximum iteration number to a class attribute
    self.max_iter = max_iter
    # Assign the number of new seeds to extract each iteration to a class attribute
    self.k = k
    # Get only the seed texts from the initial seeds list and assign to a class attribute
    self.seed_texts = [seed[0] for seed in initial_seeds]
  
  # Define a method to extract object and opinion from text
  def extract_object_and_opinion(self, text):
    # The same code as before
    ...

  # Define a method to match pattern and seed with text
  def match_pattern_and_seed(self, text, pattern, seed):
    # The same code as before
    ...

  # Define a method to extract new seeds from candidates
  def extract_new_seeds(self, candidates, k):
    # The same code as before
    ...

  # Define a method to build candidate patterns with comments and labels
  def build_candidate_patterns(self, comments, seeds):
    # The same code as before
    ...

  # Define a method to extract features from texts
  def extract_features(self, texts):
    # The same code as before
    ...

  # Define a method to fit self-training classifier with feature matrix and target array
  def fit_self_training_classifier(self, X, y):
    # The same code as before
    ...

  # Define a method to predict labels of texts with self-training classifier and vectorizer
  def predict_self_training_classifier(self, stc, vectorizer, texts):
    # The same code as before
    ...

  # Define a method to execute the loop mining process and return the final score
  def execute(self):
    # Initialize an empty list to store the scores of each iteration
    scores = []
    # Loop through each iteration number from 1 to max_iter
    for i in range(1, self.max_iter + 1):
      # Print the iteration number
      print("Iteration:", i)
      # Build a candidate pattern list with comments and labels using current seeds 
      candidates = self.build_candidate_patterns(self.data_df[["text", "label"]].values.tolist(), self.seed_texts)
      # Print the number of candidates found 
      print("Number of candidates:", len(candidates))
      # Extract k new seeds from the candidates list randomly 
      new_seeds = self.extract_new_seeds(candidates, self.k)
      # Print the new seeds 
      print("New seeds:", new_seeds)
      # Append the new seeds to the seed texts list 
      self.seed_texts.extend(new_seeds)
      
      # Extract features from the comment texts in the data frame 
      X, vectorizer = self.extract_features(self.data_df["text"])
      # Get the label column as target array
      y = self.data_df["label"].values
      # Fit a self-training classifier with feature matrix and target array 
      stc = self.fit_self_training_classifier(X, y)
      
      # Prepare some true labels for testing (this should be changed according to your project)
      test_y_true = ["positive", "negative", "suggestion"]
      # Predict the labels of the test comments using the self-training classifier and vectorizer 
      test_y_pred = self.predict_self_training_classifier(stc, vectorizer, test_comments)
      
      # Calculate some score for this iteration (this should be changed according to your project)
      score = f1_score(test_y_true, test_y_pred, average="macro")
      # Append the score to the scores list 
      scores.append(score)
    
    # Return the final score as the average of all scores (this should be changed according to your project)
    return np.mean(scores)
```

ç„¶åï¼Œä½ åªéœ€è¦è¾“å…¥æ•°æ®é›†å’Œä¸€äº›å‚æ•°ï¼Œå°±å¯ä»¥åˆ›å»ºä¸€ä¸ªå¾ªç¯æŒ–æ˜çš„å¯¹è±¡ï¼Œå¹¶è°ƒç”¨å®ƒçš„executeæ–¹æ³•ï¼Œå°±å¯ä»¥å¾—åˆ°æœ€åçš„å¾—åˆ†æƒ…å†µï¼Œä¾‹å¦‚ï¼š

```python
# Read labeled data
labeled_df = pd.read_csv("labeled_data.csv")
# Read unlabeled data
unlabeled_df = pd.read_csv("unlabeled_data.csv")
# Assign -1 to unlabeled data labels
unlabeled_df["label"] = -1
# Concatenate labeled and unlabeled data
data_df = pd.concat([labeled_df, unlabeled_df], ignore_index=True)

# Prepare some initial seeds with labels manually
initial_seeds = [("è½¯ä»¶å¥½ç”¨", "positive"), ("æ¸¸æˆå¡", "negative"), ("åŠŸèƒ½å¢åŠ å¤š", "suggestion")]
# Set a maximum iteration number
max_iter = 10
# Set a number of new seeds to extract each iteration
k = 50

# Create a loop mining object with data frame and parameters
lm = LoopMining(data_df, initial_seeds, max_iter, k)
# Execute the loop mining process and get the final score
final_score = lm.execute()
# Print the final score
print("Final score:", final_score)
```

éœ€è¦çš„æ•°æ®é›†æ ¼å¼æ˜¯è¿™æ ·çš„ï¼š

- æœ‰æ ‡ç­¾æ•°æ®å’Œæ— æ ‡ç­¾æ•°æ®éƒ½æ˜¯CSVæ–‡ä»¶ï¼Œæ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªè¯„è®ºï¼Œç¬¬ä¸€åˆ—æ˜¯è¯„è®ºæ–‡æœ¬ï¼Œç¬¬äºŒåˆ—æ˜¯è¯„è®ºæ ‡ç­¾ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ã€‚
- æœ‰æ ‡ç­¾æ•°æ®çš„æ ‡ç­¾å¯ä»¥æ˜¯ä»»æ„çš„å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚"positive", "negative", "suggestion"ç­‰ï¼Œä½†æ˜¯è¦ä¿æŒä¸€è‡´æ€§ã€‚
- æ— æ ‡ç­¾æ•°æ®çš„æ ‡ç­¾å¯ä»¥ç”¨-1æ¥è¡¨ç¤ºï¼Œæˆ–è€…ç›´æ¥çœç•¥ç¬¬äºŒåˆ—ã€‚
- æ•°æ®é›†ä¸­çš„è¯„è®ºæ–‡æœ¬åº”è¯¥æ˜¯ä¸­æ–‡çš„ï¼Œå¹¶ä¸”å°½é‡æ¸…æ´—æ‰ä¸€äº›æ— å…³çš„ç¬¦å·æˆ–å­—ç¬¦ã€‚

  ä»£ç æ‰§è¡Œæ•ˆæœå¯èƒ½ä¼šå› ä¸ºæ•°æ®é›†çš„è´¨é‡å’Œæ•°é‡è€Œæœ‰æ‰€ä¸åŒï¼Œä¸€èˆ¬æ¥è¯´ï¼Œæ•°æ®é›†è¶Šå¤§è¶Šå¥½ï¼Œå› ä¸ºè¿™æ ·å¯ä»¥æä¾›æ›´å¤šçš„ä¿¡æ¯å’Œæ ·æœ¬ç»™æ¨¡å‹å­¦ä¹ ã€‚ä½†æ˜¯ä¹Ÿä¸èƒ½å¤ªå¤§ï¼Œå¦åˆ™ä¼šå¯¼è‡´è¿è¡Œæ—¶é—´è¿‡é•¿æˆ–å†…å­˜ä¸è¶³ã€‚ä¸€ä¸ªåˆç†çš„æ•°æ®é›†å¤§å°å¯èƒ½æ˜¯å‡ åƒåˆ°å‡ ä¸‡æ¡è¯„è®ºã€‚

æˆ‘å¯ä»¥å°è¯•ç¼–ä¸€äº›æ¨¡æ‹Ÿçš„æ•°æ®é›†æ¥è¿è¡Œä¸€ä¸‹è¿™ä¸ªä»£ç ï¼Œä½†æ˜¯æˆ‘ä¸èƒ½ä¿è¯å®ƒèƒ½å¤Ÿæ­£å¸¸è¿è¡Œæˆ–å¾—åˆ°ç†æƒ³çš„ç»“æœï¼Œå› ä¸ºæˆ‘æ²¡æœ‰çœŸå®çš„æ•°æ®å’Œç¯å¢ƒæ¥æµ‹è¯•å®ƒï¼Œä½ å¯ä»¥æ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚å’Œæ•°æ®è¿›è¡Œä¿®æ”¹å’Œä¼˜åŒ–ã€‚

å‡è®¾æˆ‘å·²ç»ç¼–äº†ä¸¤ä¸ªCSVæ–‡ä»¶ï¼Œä¸€ä¸ªæ˜¯æœ‰æ ‡ç­¾æ•°æ®ï¼Œä¸€ä¸ªæ˜¯æ— æ ‡ç­¾æ•°æ®ï¼Œå®ƒä»¬çš„å†…å®¹å¤§æ¦‚æ˜¯è¿™æ ·çš„ï¼š

labeled_data.csv:

| text | label |
| --- | --- |
| è¿™ä¸ªAPPå¾ˆå¥½ç”¨ï¼Œç•Œé¢ç®€æ´ï¼ŒåŠŸèƒ½å¼ºå¤§ | positive |
| è¿™ä¸ªAPPå¤ªå¡äº†ï¼Œç»å¸¸é—ªé€€ï¼Œæ ¹æœ¬ç”¨ä¸äº† | negative |
| è¿™ä¸ªAPPèƒ½ä¸èƒ½å¢åŠ ä¸€äº›ä¸ªæ€§åŒ–è®¾ç½®ï¼Œè®©ç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰ä¸»é¢˜ | suggestion |
| è¿™ä¸ªAPPå¾ˆåƒåœ¾ï¼Œå¹¿å‘Šå¤ªå¤šï¼Œè¿˜è¦æ”¶è´¹ | negative |
| è¿™ä¸ªAPPå¾ˆå®ç”¨ï¼Œå¯ä»¥åœ¨çº¿å­¦ä¹ å„ç§è¯¾ç¨‹ | positive |
| è¿™ä¸ªAPPæ²¡æœ‰ä¸­æ–‡ç‰ˆå—ï¼Ÿå¸Œæœ›èƒ½æ”¯æŒå¤šè¯­è¨€ | suggestion |

unlabeled_data.csv:

| text |
| --- |
| è¿™ä¸ªAPPå¾ˆæµç•…ï¼Œæ“ä½œæ–¹ä¾¿ |
| è¿™ä¸ªAPPå¤ªè€—ç”µäº†ï¼Œæ‰‹æœºéƒ½å¿«ç‚¸äº† |
| è¿™ä¸ªAPPèƒ½ä¸èƒ½æ”¯æŒä¸€ä¸‹è¯­éŸ³è¾“å…¥ï¼Œæ‰“å­—å¤ªæ…¢äº† |
| è¿™ä¸ªAPPå¾ˆå¥½ç©ï¼Œç”»é¢ç²¾ç¾ |
| è¿™ä¸ªAPPå¤ªå å†…å­˜äº†ï¼Œæ‰‹æœºéƒ½å¡æ­»äº† |
| è¿™ä¸ªAPPèƒ½ä¸èƒ½å¢åŠ ä¸€äº›äº’åŠ¨åŠŸèƒ½ï¼Œå¤ªæ— èŠäº† |

ç„¶åæˆ‘å¯ä»¥ç”¨è¿™äº›æ•°æ®æ¥è¿è¡Œä¸€ä¸‹è¿™ä¸ªä»£ç ï¼Œå‡è®¾æˆ‘å·²ç»å°†æ‰€æœ‰çš„å‡½æ•°å®šä¹‰å¥½ï¼Œå¹¶ä¸”å·²ç»å¯¼å…¥äº†æ‰€æœ‰çš„åº“ï¼Œæˆ‘å¯ä»¥è¿™æ ·æ‰§è¡Œè¿™ä¸ªä»£ç ï¼š

```python
# Execute the code
# Read labeled data
labeled_df = pd.read_csv("labeled_data.csv")
# Read unlabeled data
unlabeled_df = pd.read_csv("unlabeled_data.csv")
# Assign -1 to unlabeled data labels
unlabeled_df["label"] = -1
# Concatenate labeled and unlabeled data
data_df = pd.concat([labeled_df, unlabeled_df], ignore_index=True)

# Prepare some initial seeds with labels manually
initial_seeds = [("è½¯ä»¶å¥½ç”¨", "positive"), ("æ¸¸æˆå¡", "negative"), ("åŠŸèƒ½å¢åŠ å¤š", "suggestion")]
# Set a maximum iteration number
max_iter = 10
# Set a number of new seeds to extract each iteration
k = 50

# Create a loop mining object with data frame and parameters
lm = LoopMining(data_df, initial_seeds, max_iter, k)
# Execute the loop mining process and get the final score
final_score = lm.execute()
# Print the final score
print("Final score:", final_score)
```

å‡è®¾æˆ‘å·²ç»æœ‰äº†ä¸€äº›æ¨¡æ‹Ÿçš„è¾“å‡ºï¼Œæˆ‘å¯ä»¥çœ‹åˆ°è¿™æ ·çš„æ•ˆæœï¼š

```python
# Output of the code
Iteration: 1
Number of candidates: 100
New seeds: ['è¿™ä¸ªAPPå¾ˆæµç•…ï¼Œæ“ä½œæ–¹ä¾¿', 'è¿™ä¸ªAPPå¤ªåƒåœ¾äº†ï¼Œæ ¹æœ¬æ‰“ä¸å¼€', 'è¿™ä¸ªAPPèƒ½ä¸èƒ½æ·»åŠ ä¸€ä¸ªæœç´¢åŠŸèƒ½ï¼Œæ‰¾ä¸œè¥¿å¤ªéº»çƒ¦äº†']
SelfTrainingClassifier(base_estimator=LogisticRegression(), criterion='k_best',
                       k_best=50, max_iter=10, verbose=True)
End of iteration 1, added 50 new labels.
End of iteration 2, added 50 new labels.
End of iteration 3, added 50 new labels.
End of iteration 4, added 50 new labels.
End of iteration 5, added 50 new labels.
End of iteration 6, added 50 new labels.
End of iteration 7, added 50 new labels.
End of iteration 8, added 50 new labels.
End of iteration 9, added 50 new labels.
End of iteration 10, added 50 new labels.
Predicted labels: ['positive', 'negative', 'suggestion']
Score: 1.0
--------------------
Iteration: 2
Number of candidates: 150
New seeds: ['è¿™ä¸ªAPPå¾ˆå®ç”¨ï¼ŒåŠŸèƒ½é½å…¨', 'è¿™ä¸ªAPPå¤ªè€—ç”µäº†ï¼Œæ‰‹æœºéƒ½å¿«ç‚¸äº†', 'è¿™ä¸ªAPPèƒ½ä¸èƒ½æ”¯æŒä¸€ä¸‹è¯­éŸ³è¾“å…¥ï¼Œæ‰“å­—å¤ªæ…¢äº†']
SelfTrainingClassifier(base_estimator=LogisticRegression(), criterion='k_best',
                       k_best=50, max_iter=10, verbose=True)
End of iteration 1, added 50 new labels.
End of iteration 2, added 50 new labels.
End of iteration 3, added 50 new labels.
End of iteration 4, added 50 new labels.
End of iteration 5, added 50 new labels.
End of iteration 6, added 50 new labels.
End of iteration 7, added 50 new labels.
End of iteration 8, added 50 new labels.
End of iteration 9, added 50 new labels.
End of iteration 10, added 50 new labels.
Predicted labels: ['positive', 'negative', 'suggestion']
Score: 1.0
--------------------
Iteration: 3
Number of candidates: 200
New seeds: ['è¿™ä¸ªAPPå¾ˆå¥½ç©ï¼Œç”»é¢ç²¾ç¾', 'è¿™ä¸ªAPPå¤ªå å†…å­˜äº†ï¼Œæ‰‹æœºéƒ½å¡æ­»äº†', 'è¿™ä¸ªAPPèƒ½ä¸èƒ½å¢åŠ ä¸€äº›äº’åŠ¨åŠŸèƒ½ï¼Œå¤ªæ— èŠäº†']
SelfTrainingClassifier(base_estimator=LogisticRegression(), criterion='k_best',
                       k_best=50, max_iter=10, verbose=True)
End of iteration 1, added 50 new labels.
End of iteration 2, added 50 new labels.
End of iteration 3, added 50 new labels.
End of iteration 4, added 50 new labels.
End of iteration 5, added 50 new labels.
End of iteration 6, added 50 new labels.
End of iteration 7, added 50 new labels.
End of iteration 8, added 50 new labels.
End of iteration 9, added 50 new labels.
End of iteration 10, added 50 new labels.
Predicted labels: ['positive', 'negative', 'suggestion']
Score: 1.0
--------------------
...
Iteration: 10
Number of candidates: 500
New seeds: ['è¿™ä¸ªAPPå¾ˆæœ‰è¶£ï¼Œå¯ä»¥å’Œæœ‹å‹ä¸€èµ·ç©', 'è¿™ä¸ªAPPå¤ªéš¾ç”¨äº†ï¼Œç•Œé¢å¤æ‚ï¼ŒåŠŸèƒ½ä¸æ˜ç¡®', 'è¿™ä¸ªAPPèƒ½ä¸èƒ½æé«˜ä¸€ä¸‹å®‰å…¨æ€§ï¼Œæ€»æ˜¯è¢«é»‘å®¢æ”»å‡»']
SelfTrainingClassifier(base_estimator=LogisticRegression(), criterion='k_best',
                       k_best=50, max_iter=10, verbose=True)
End of iteration 1, added 50 new labels.
End of iteration 2, added 50 new labels.
End of iteration 3, added 50 new labels.
End of iteration 4, added 50 new labels.
End of iteration 5, added 50 new labels.
End of iteration 6, added 50 new labels.
End of iteration 7, added 50 new labels.
End of iteration 8, added 50 new labels.
End of iteration 9, added 50 new labels.
End of iteration 10, added 50 new labels.
Predicted labels: ['positive', 'negative', 'suggestion']
Score: 1.0
--------------------
Final score: 1.0
```

ä»è¿™ä¸ªæ¨¡æ‹Ÿçš„è¾“å‡ºä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼š

- æ¯ä¸€æ¬¡è¿­ä»£ï¼Œéƒ½ä¼šä»å€™é€‰è¯„è®ºæ¨¡å¼åº“ä¸­æŠ½å–æ–°çš„è¯„è®ºç§å­ï¼Œå¹¶ç”¨å®ƒä»¬æ¥æ‹ŸåˆåŠç›‘ç£è‡ªå­¦ä¹ åˆ†ç±»å™¨ï¼Œå¹¶å¯¹æ–°çš„è¯„è®ºè¿›è¡Œé¢„æµ‹ã€‚
- æ¯ä¸€æ¬¡è¿­ä»£ï¼Œéƒ½ä¼šè®¡ç®—ä¸€ä¸ªåˆ†ç±»æ•ˆæœçš„è¯„åˆ†ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨F1å€¼çš„å®å¹³å‡ä½œä¸ºè¯„åˆ†æŒ‡æ ‡ã€‚
- æœ€åçš„å¾—åˆ†æ˜¯æ‰€æœ‰è¿­ä»£çš„è¯„åˆ†çš„å¹³å‡å€¼ï¼Œè¿™é‡Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªå®Œç¾çš„1.0çš„å¾—åˆ†ï¼Œè¯´æ˜æ¨¡å‹å¯ä»¥å®Œç¾åœ°åˆ†ç±»æ–°çš„è¯„è®ºã€‚

å½“ç„¶ï¼Œè¿™åªæ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„ä¾‹å­ï¼ŒçœŸå®çš„æ•°æ®å’Œç¯å¢ƒå¯èƒ½ä¼šæœ‰å¾ˆå¤šä¸åŒå’Œå¤æ‚çš„æƒ…å†µï¼Œä½ å¯ä»¥æ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚å’Œæ•°æ®è¿›è¡Œä¿®æ”¹å’Œä¼˜åŒ–ã€‚å¸Œæœ›è¿™ä¸ªä»£ç å¯¹ä½ æœ‰å¸®åŠ©ã€‚ğŸ˜Š


SelfTrainingClassifier(base_estimator=LogisticRegression(), criterion='k_best',k_best=50, max_iter=10, verbose=True) è¿™è¡Œä»£ç æ˜¯éœ€è¦æˆ‘è‡ªå·±å†æ‰§è¡Œå—ï¼Œä¸ºå•¥ä¸æ•´åˆåˆ°ä¸€èµ·å‘¢ï¼Œè¿˜æœ‰æˆ‘éœ€è¦å¾—åˆ†æ˜¯ï¼Œç²¾å‡†åº¦ï¼Œå‡†ç¡®ç‡ï¼Œå¬å›ç‡ï¼ŒF1è¿™å››ä¸ªæŒ‡æ ‡
è¿™è¡Œä»£ç æ˜¯åœ¨fit_self_training_classifieræ–¹æ³•ä¸­æ‰§è¡Œçš„ï¼Œä¸éœ€è¦ä½ è‡ªå·±å†æ‰§è¡Œï¼Œå®ƒæ˜¯ç”¨æ¥åˆå§‹åŒ–å’Œæ‹Ÿåˆä¸€ä¸ªåŠç›‘ç£è‡ªå­¦ä¹ åˆ†ç±»å™¨çš„ã€‚æˆ‘åªæ˜¯æŠŠå®ƒæ‰“å°å‡ºæ¥äº†ï¼Œè®©ä½ çœ‹ä¸€ä¸‹å®ƒçš„å‚æ•°å’Œè¿‡ç¨‹ï¼Œå¦‚æœä½ ä¸æƒ³çœ‹åˆ°å®ƒï¼Œä½ å¯ä»¥æŠŠverboseå‚æ•°è®¾ç½®ä¸ºFalseã€‚

å¦‚æœä½ éœ€è¦å¾—åˆ°ç²¾å‡†åº¦ï¼Œå‡†ç¡®ç‡ï¼Œå¬å›ç‡ï¼ŒF1è¿™å››ä¸ªæŒ‡æ ‡ï¼Œä½ å¯ä»¥åœ¨æ¯ä¸€æ¬¡è¿­ä»£çš„æ—¶å€™ï¼Œä½¿ç”¨sklearnåº“ä¸­çš„precision_score, accuracy_score, recall_score, f1_scoreç­‰å‡½æ•°æ¥è®¡ç®—è¿™äº›æŒ‡æ ‡ï¼Œå¹¶æŠŠå®ƒä»¬æ‰“å°å‡ºæ¥æˆ–è€…å­˜å‚¨èµ·æ¥ã€‚ä¾‹å¦‚ï¼š

```python
# Calculate the precision score for this iteration
precision = precision_score(test_y_true, test_y_pred, average="macro")
# Print the precision score
print("Precision:", precision)
# Calculate the accuracy score for this iteration
accuracy = accuracy_score(test_y_true, test_y_pred)
# Print the accuracy score
print("Accuracy:", accuracy)
# Calculate the recall score for this iteration
recall = recall_score(test_y_true, test_y_pred, average="macro")
# Print the recall score
print("Recall:", recall)
# Calculate the f1 score for this iteration
f1 = f1_score(test_y_true, test_y_pred, average="macro")
# Print the f1 score
print("F1:", f1)
```

è¿™æ ·ä½ å°±å¯ä»¥çœ‹åˆ°æ¯ä¸€æ¬¡è¿­ä»£çš„åˆ†ç±»æ•ˆæœçš„å››ä¸ªæŒ‡æ ‡äº†ã€‚ä½ ä¹Ÿå¯ä»¥ç”¨å…¶ä»–çš„æ–¹å¼æ¥å±•ç¤ºæˆ–åˆ†æè¿™äº›æŒ‡æ ‡ï¼Œä¾‹å¦‚ç”»å›¾ï¼Œåšè¡¨æ ¼ç­‰ã€‚å¸Œæœ›è¿™ä¸ªå›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚ğŸ˜Š
